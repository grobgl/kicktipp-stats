{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KT = \"https://www.kicktipp.de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "    def __init__(self, spieltag=1, group='twitter-kicktipp'):\n",
    "        form_data = {'kennung': os.environ['EMAIL'], 'passwort': os.environ['PASSWORD']} \n",
    "        login_post_url = f\"{KT}/info/profil/loginaction\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.post(login_post_url, data=form_data)\n",
    "        self.spieltag = spieltag\n",
    "        self.group = group\n",
    "        \n",
    "    def fetch_url(self, url):\n",
    "        response = self.session.get(url)\n",
    "        html = response.text\n",
    "        self.soup = BeautifulSoup(html, \"html5lib\")\n",
    "\n",
    "    def get_predictions(self):\n",
    "        scraper.fetch_url(f\"{KT}/{self.group}/tippuebersicht?&spieltagIndex={self.spieltag}\")\n",
    "        pairings = list(self._get_pairings())\n",
    "        predictions = {p: {'result': self._get_match_result(i), 'predictions': self._get_match_predictions(i)} for i,p in enumerate(pairings)}\n",
    "        if len(self.soup.select('.blaettern .down')):\n",
    "            offset = 40\n",
    "            scraper.fetch_url(f\"{KT}/{self.group}/tippuebersicht?&spieltagIndex={self.spieltag}&offset={offset}\")\n",
    "            for i,p in enumerate(pairings):\n",
    "                predictions[p]['predictions'] = pd.concat([predictions[p]['predictions'], self._get_match_predictions(i)])\n",
    "            while len(self.soup.select('.blaettern .down')) == 2:\n",
    "                offset += 20\n",
    "                self.fetch_url(f\"{KT}/{self.group}/tippuebersicht?&spieltagIndex={self.spieltag}&offset={offset}\")\n",
    "                for i,p in enumerate(pairings):\n",
    "                    new_pred = self._get_match_predictions(i)\n",
    "                    predictions[p]['predictions'] = pd.concat([predictions[p]['predictions'], new_pred])\n",
    "        return predictions\n",
    "                \n",
    "    def _get_pairings(self):\n",
    "        home = self._get_text(self.soup.select('.headerEreignis.heim .ereignis'))\n",
    "        away = self._get_text(self.soup.select('.headerEreignis.gast .ereignis'))\n",
    "        return (f'{h}-{a}' for h,a in zip(home, away))\n",
    "\n",
    "    def _get_match_result(self, match_index):\n",
    "        home = list(self._get_text(self.soup.select(f'th.ereignis{match_index} .kicktipp-heim')))[0]\n",
    "        away = list(self._get_text(self.soup.select(f'th.ereignis{match_index} .kicktipp-gast')))[0]\n",
    "        return (int(home), int(away)) if home.isdigit() else (0,0)\n",
    "    \n",
    "    def _get_match_predictions(self, match_index):\n",
    "        preds = self._get_text(self.soup.select(f'td.nw.ereignis.ereignis{match_index}'))\n",
    "        pred_pairs = list(map(lambda p: tuple(map(lambda x: int(x) if x.isdigit() else 0, p.split(':') if p else ())), preds))\n",
    "        if len(self.soup.select('.blaettern .up')):\n",
    "            pred_pairs = pred_pairs[20:]\n",
    "        filtered = (p for p in pred_pairs if p)\n",
    "        return pd.DataFrame(filtered, columns=[\"HOME\", \"AWAY\"])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_text(soups):\n",
    "        return map(lambda x: x.contents[0] if x.contents else '', soups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = Scraper(spieltag=4)#, group='grobefamilie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scraper.get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    def __init__(self, predictions):\n",
    "        self.predictions = predictions\n",
    "        self.pairings = predictions.keys()\n",
    "        \n",
    "    def plot_predictions(self, pairing):\n",
    "        pds = predictions[pairing]['predictions']\n",
    "        pds = pds[pds['HOME'] <= 10]\n",
    "        pds = pds[pds['AWAY'] <= 10]\n",
    "        res = predictions[pairing]['result']\n",
    "#         max_home = max(res[0], pds.HOME.max())\n",
    "#         max_away = max(res[1], pds.AWAY.max())\n",
    "        max_home = 8\n",
    "        max_away = 8\n",
    "        \n",
    "        pds = pds.groupby(['HOME', 'AWAY']).size()\n",
    "        for i in range(max_home+1):\n",
    "            for j in range(max_away+1):\n",
    "                if (i,j) not in pds.index:\n",
    "                    pds[(i,j)] = 0\n",
    "\n",
    "        pds = pd.DataFrame({'COUNT' : pds}).reset_index()\n",
    "        pds = pds.pivot('HOME', 'AWAY', 'COUNT')\n",
    "        pds.sort_index(level=0, ascending=False, inplace=True)\n",
    "\n",
    "        f, ax = plt.subplots(figsize=(9, 6))\n",
    "        sns.heatmap(pds, annot=True, fmt=\"d\", linewidths=.5, ax=ax, cmap=\"BuPu\", cbar=False)\n",
    "        rec = plt.Rectangle((res[1],max_home - res[0]),1,1, fill=False,\n",
    "                            edgecolor=\"crimson\", lw=2 )\n",
    "        ax.add_artist(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotter = Plotter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500724728d164a11bd32c3a61844be5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='pairing', options=('DEN-AUS', 'FRA-PER', 'ARG-KRO', 'BRA-CRC', 'NIâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(plotter.plot_predictions, pairing=plotter.pairings);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
